{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944efb72",
   "metadata": {},
   "source": [
    "# 9章 素性ベースの文法の構築"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e75802",
   "metadata": {},
   "source": [
    "自然言語には，8章で説明したような単純な方法では扱いが難しい文法的構造が広範囲にわたって存在する．そこで柔軟性を確保するために，SやNP，Vといった文法範疇の扱いを変えることにする．アトミックなラベルの代わりに，それらを辞書のような構造に分解し，素性が様々な値を取ることができるようにするのだ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e71116",
   "metadata": {},
   "source": [
    "## 本章の目的\n",
    "1. 文脈自由文法の枠組みを拡張し，文法範疇と生成規則をより詳細に制御するにはどうすればよいか．\n",
    "\n",
    "2. 素性構造の形式特性は主に何で，どのように計算によって扱えばよいか．\n",
    "\n",
    "3. 素性ベースの文法を用いると，どのような種類の言語パターンや文法生成規則を扱うことができるか．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef50852c",
   "metadata": {},
   "source": [
    "# 9.1 文法素性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "kim = {'CAT': 'NP', 'ORTH': 'Kim', 'REF': 'k'}\n",
    "chase = {'CAT': 'V', 'ORTH': 'chased', 'REL': 'chase'}\n",
    "\n",
    "# sub(主語)とobj(目的語)を動詞が文法項と結合したときに埋められる\n",
    "# プレースホルダとして使う．\n",
    "\n",
    "chase['AGT'] = 'sbj'\n",
    "chase['PAT'] = 'obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb62f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kim Kim\n",
      "{'CAT': 'NP', 'ORTH': 'Kim', 'REF': 'k'}\n",
      "chased chased\n",
      "{'CAT': 'V', 'ORTH': 'chased', 'REL': 'chase', 'AGT': 'sbj', 'PAT': 'obj'}\n",
      "Lee Lee\n",
      "{'CAT': 'NP', 'ORTH': 'Lee', 'REF': 'l'}\n",
      "ORTH  => chased\n",
      "REL   => chase\n",
      "AGT   => k\n",
      "PAT   => l\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "sent = \"Kim chased Lee\"\n",
    "tokens = sent.split()\n",
    "lee = {'CAT': 'NP', 'ORTH': 'Lee', 'REF': 'l'}\n",
    "\n",
    "# fsの各要素のorthographyが引数と一致すればそれを返す\n",
    "\n",
    "def lex2fs(word):\n",
    "    for fs in [kim, lee, chase]:\n",
    "        if fs['ORTH'] == word:\n",
    "            print(fs['ORTH'], word)\n",
    "            print(fs)\n",
    "            return fs\n",
    "        \n",
    "# 3つの変数に関数の返り値を代入\n",
    "\n",
    "subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2])\n",
    "\n",
    "verb['AGT'] = subj['REF']     # agent of 'chase' is Kim\n",
    "verb['PAT'] = obj['REF']      # patient of 'chase' is Lee\n",
    "\n",
    "# check featstruct of 'chase'\n",
    "for k in ['ORTH', 'REL', 'AGT', 'PAT']:\n",
    "    print(\"%-5s => %s\" % (k, verb[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265f66e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "# S expansion productions\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# NP expansion productions\n",
      "NP[NUM=?n] -> N[NUM=?n] \n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
      "NP[NUM=pl] -> N[NUM=pl] \n",
      "# VP expansion productions\n",
      "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "Det[NUM=sg] -> 'this' | 'every'\n",
      "Det[NUM=pl] -> 'these' | 'all'\n",
      "Det -> 'the' | 'some' | 'several'\n",
      "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
      "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
      "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children' \n",
      "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
      "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
      "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
      "TV[TENSE=past] -> 'saw' | 'liked'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.data.show_cfg('grammars/book_grammars/feat0.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aed00e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Kim .like.chil.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'Kim'\n",
      "|.    [----]    .| [1:2] 'likes'\n",
      "|.    .    [----]| [2:3] 'children'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
      "  (VP[NUM='sg', TENSE='pres']\n",
      "    (TV[NUM='sg', TENSE='pres'] likes)\n",
      "    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'Kim likes children'.split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/feat0.fcfg', trace=2)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68bd95a",
   "metadata": {},
   "source": [
    "# 9.2 素性構造の処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d2158b",
   "metadata": {},
   "source": [
    "本節ではNLTKで素性構造をどのように構築，操作するかについて解説する．さらに２つの異なる素性構造に含まれる情報を統合する方法である，単一化という基本操作についてみていく．NLTKではFeatStruct()コンストラクタを用いて素性構造を宣言できる．アトミックな素性値としては，文字列もしくは整数を用いることができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac36830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NUM   = 'sg'   ]\n",
      "[ TENSE = 'past' ]\n",
      "fem\n",
      "[ CASE = 'acc' ]\n",
      "[ GND  = 'fem' ]\n",
      "[ NUM  = 'p1'  ]\n",
      "[ PER  = 3     ]\n",
      "[       [ CASE = 'acc' ] ]\n",
      "[ AGR = [ GND  = 'fem' ] ]\n",
      "[       [ NUM  = 'p1'  ] ]\n",
      "[       [ PER  = 3     ] ]\n",
      "[                        ]\n",
      "[ POS = 'N'              ]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "fs1 = nltk.FeatStruct(TENSE='past', NUM='sg')\n",
    "print(fs1)\n",
    "\n",
    "# 基本的な操作は辞書と同じ\n",
    "\n",
    "fs1 = nltk.FeatStruct(PER=3, NUM='p1', GND='fem')\n",
    "print(fs1['GND'])\n",
    "fs1['CASE'] = 'acc'\n",
    "print(fs1)\n",
    "\n",
    "# 複合値を持つ素性構造も定義できる\n",
    "\n",
    "fs2 = nltk.FeatStruct(POS='N', AGR=fs1)\n",
    "print(fs2)\n",
    "print(fs2['AGR']['PER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef6bcda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       [ GND = 'fem' ] ]\n",
      "[ AGR = [ NUM = 'p1'  ] ]\n",
      "[       [ PER = 3     ] ]\n",
      "[                       ]\n",
      "[ POS = 'N'             ]\n"
     ]
    }
   ],
   "source": [
    "# 素性構造を定義するほかの方法として，素性と値のペアを「素性＝値」の形式で\n",
    "# 表現したカッコつき文字列を用いることもできる\n",
    "\n",
    "print(nltk.FeatStruct(\"[POS='N', AGR=[PER=3, NUM='p1', GND='fem']]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d746bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ age   = 33               ]\n",
      "[ name  = 'Lee'            ]\n",
      "[ telno = '01 27 86 42 96' ]\n"
     ]
    }
   ],
   "source": [
    "# 素性構造を用いて，人物に関する情報を符号化することもできる\n",
    "\n",
    "print(nltk.FeatStruct(name='Lee', telno='01 27 86 42 96', age=33))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c578f0",
   "metadata": {},
   "source": [
    "素性構造をグラフ，具体的には無閉路有効グラフ（DAG）として表現すると便利なことがある．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc0902",
   "metadata": {},
   "source": [
    "再入を行列的表現によって表示するには，共有素性構造が最初に出現するときに(1)のように括弧つき整数によって接頭辞をつける．この構造を以降参照する場合にはすべて->(1)という表記を用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1119bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ADDRESS = (1) [ NUMBER = 74           ] ]\n",
      "[               [ STREET = 'rue Pascal' ] ]\n",
      "[                                         ]\n",
      "[ NAME    = 'Lee'                         ]\n",
      "[                                         ]\n",
      "[ SPOUSE  = [ ADDRESS -> (1)  ]           ]\n",
      "[           [ NAME    = 'Kim' ]           ]\n",
      "--------------------------------------\n",
      "[ A = 'a'             ]\n",
      "[                     ]\n",
      "[ B = (1) [ C = 'c' ] ]\n",
      "[                     ]\n",
      "[ D -> (1)            ]\n",
      "[ E -> (1)            ]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "print(nltk.FeatStruct(\"\"\"[NAME='Lee',\n",
    "    ADDRESS=(1)[NUMBER=74, STREET='rue Pascal'],\n",
    "    SPOUSE=[NAME='Kim', ADDRESS->(1)]]\"\"\"))\n",
    "\n",
    "# 単一の素性構造にどれだけタグを含めてもよい\n",
    "print('--------------------------------------')\n",
    "print(nltk.FeatStruct(\"[A='a', B=(1)[C='c'], D->(1), E->(1)]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94fed714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ CITY   = 'Paris'      ]\n",
      "[ NUMBER = 74           ]\n",
      "[ STREET = 'rue Pascal' ]\n",
      "------------------------------------------------------\n",
      "[ CITY   = 'Paris'      ]\n",
      "[ NUMBER = 74           ]\n",
      "[ STREET = 'rue Pascal' ]\n"
     ]
    }
   ],
   "source": [
    "# 2つの素性構造の情報を合併する操作は単一化と呼ばれ，unify()メソッドを利用\n",
    "\n",
    "fs1 = nltk.FeatStruct(NUMBER=74, STREET='rue Pascal')\n",
    "fs2 = nltk.FeatStruct(CITY='Paris')\n",
    "print(fs1.unify(fs2))\n",
    "\n",
    "# 単一化は対照的である\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "print(fs2.unify(fs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93c0c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# 単一化の失敗\n",
    "\n",
    "fs0 = nltk.FeatStruct(A='a')\n",
    "fs1 = nltk.FeatStruct(A='b')\n",
    "fs2 = fs0.unify(fs1)\n",
    "print(fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ce08c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ADDRESS = [ NUMBER = 74           ]               ]\n",
      "[           [ STREET = 'rue Pascal' ]               ]\n",
      "[                                                   ]\n",
      "[ NAME    = 'Lee'                                   ]\n",
      "[                                                   ]\n",
      "[           [ ADDRESS = [ NUMBER = 74           ] ] ]\n",
      "[ SPOUSE  = [           [ STREET = 'rue Pascal' ] ] ]\n",
      "[           [                                     ] ]\n",
      "[           [ NAME    = 'Kim'                     ] ]\n"
     ]
    }
   ],
   "source": [
    "fs0 = nltk.FeatStruct(\"\"\"[NAME=Lee,\n",
    "                              ADDRESS=[NUMBER=74,\n",
    "                              STREET='rue Pascal'],\n",
    "                          SPOUSE= [NAME=Kim,\n",
    "                              ADDRESS=[NUMBER=74,\n",
    "                              STREET='rue Pascal']]]\"\"\")\n",
    "\n",
    "print(fs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2d84b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ADDRESS = [ NUMBER = 74           ]               ]\n",
      "[           [ STREET = 'rue Pascal' ]               ]\n",
      "[                                                   ]\n",
      "[ NAME    = 'Lee'                                   ]\n",
      "[                                                   ]\n",
      "[           [           [ CITY   = 'PARIS'      ] ] ]\n",
      "[           [ ADDRESS = [ NUMBER = 74           ] ] ]\n",
      "[ SPOUSE  = [           [ STREET = 'rue Pascal' ] ] ]\n",
      "[           [                                     ] ]\n",
      "[           [ NAME    = 'Kim'                     ] ]\n"
     ]
    }
   ],
   "source": [
    "# Kimの住所に対してCITYを定義して拡張する\n",
    "\n",
    "fs1 = nltk.FeatStruct(\"[SPOUSE = [ADDRESS = [CITY = PARIS]]]\")\n",
    "print(fs1.unify(fs0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28e85e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[               [ CITY   = 'PARIS'      ] ]\n",
      "[ ADDRESS = (1) [ NUMBER = 74           ] ]\n",
      "[               [ STREET = 'rue Pascal' ] ]\n",
      "[                                         ]\n",
      "[ NAME    = 'Lee'                         ]\n",
      "[                                         ]\n",
      "[ SPOUSE  = [ ADDRESS -> (1)  ]           ]\n",
      "[           [ NAME    = 'Kim' ]           ]\n"
     ]
    }
   ],
   "source": [
    "# 素性共有版のfs2と単一化\n",
    "fs2 = nltk.FeatStruct(\"\"\"[NAME=Lee,\n",
    "                      ADDRESS=(1)[NUMBER=74, STREET='rue Pascal'],\n",
    "                      SPOUSE=[NAME=Kim, ADDRESS->(1)]]\"\"\")\n",
    "\n",
    "print(fs1.unify(fs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476a164",
   "metadata": {},
   "source": [
    "# 9.3 素性ベースの文法の拡張"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207719fa",
   "metadata": {},
   "source": [
    "いかに示す文法は，空所を導入する生成規則を含んでいる．空所素性を正しく買いに伝播させるためには\n",
    "空所を変数値とともにS,VP,NPを展開する生成規則の両辺に追加する必要がある．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "153330b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "S[-INV] -> NP VP\n",
      "S[-INV]/?x -> NP VP/?x\n",
      "S[-INV] -> NP S/NP\n",
      "S[-INV] -> Adv[+NEG] S[+INV]\n",
      "S[+INV] -> V[+AUX] NP VP\n",
      "S[+INV]/?x -> V[+AUX] NP VP/?x\n",
      "SBar -> Comp S[-INV]\n",
      "SBar/?x -> Comp S[-INV]/?x\n",
      "VP -> V[SUBCAT=intrans, -AUX]\n",
      "VP -> V[SUBCAT=trans, -AUX] NP\n",
      "VP/?x -> V[SUBCAT=trans, -AUX] NP/?x\n",
      "VP -> V[SUBCAT=clause, -AUX] SBar\n",
      "VP/?x -> V[SUBCAT=clause, -AUX] SBar/?x\n",
      "VP -> V[+AUX] VP\n",
      "VP/?x -> V[+AUX] VP/?x\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "V[SUBCAT=intrans, -AUX] -> 'walk' | 'sing'\n",
      "V[SUBCAT=trans, -AUX] -> 'see' | 'like'\n",
      "V[SUBCAT=clause, -AUX] -> 'say' | 'claim'\n",
      "V[+AUX] -> 'do' | 'can'\n",
      "NP[-WH] -> 'you' | 'cats'\n",
      "NP[+WH] -> 'who'\n",
      "Adv[+NEG] -> 'rarely' | 'never'\n",
      "NP/NP ->\n",
      "Comp -> 'that'\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# 転置節および空所範疇を利用した長距離依存に対応する生成規則を含む文法\n",
    "\n",
    "nltk.data.show_cfg('grammars/book_grammars/feat1.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd1d20e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (NP[+WH] who)\n",
      "  (S[+INV]/NP[]\n",
      "    (V[+AUX] do)\n",
      "    (NP[-WH] you)\n",
      "    (VP[]/NP[]\n",
      "      (V[-AUX, SUBCAT='clause'] claim)\n",
      "      (SBar[]/NP[]\n",
      "        (Comp[] that)\n",
      "        (S[-INV]/NP[]\n",
      "          (NP[-WH] you)\n",
      "          (VP[]/NP[] (V[-AUX, SUBCAT='trans'] like) (NP[]/NP[] )))))))\n"
     ]
    }
   ],
   "source": [
    "# who do you claim that you like を構文解析する\n",
    "\n",
    "tokens = 'who do you claim that you like'.split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/feat1.fcfg')\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7eb72199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (NP[-WH] you)\n",
      "  (VP[]\n",
      "    (V[-AUX, SUBCAT='clause'] claim)\n",
      "    (SBar[]\n",
      "      (Comp[] that)\n",
      "      (S[-INV]\n",
      "        (NP[-WH] you)\n",
      "        (VP[] (V[-AUX, SUBCAT='trans'] like) (NP[-WH] cats))))))\n"
     ]
    }
   ],
   "source": [
    "# 空所のない文の構文解析\n",
    "\n",
    "tokens = 'you claim that you like cats'.split()\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f522c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[-INV]\n",
      "  (Adv[+NEG] rarely)\n",
      "  (S[+INV]\n",
      "    (V[+AUX] do)\n",
      "    (NP[-WH] you)\n",
      "    (VP[] (V[-AUX, SUBCAT='intrans'] sing))))\n"
     ]
    }
   ],
   "source": [
    "# wh 構造を持たない転置文を受け取る\n",
    "\n",
    "tokens = 'rarely do you sing'.split()\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b7d8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# Grammar Productions\n",
      "S -> NP[CASE=nom, AGR=?a] VP[AGR=?a]\n",
      "NP[CASE=?c, AGR=?a] -> PRO[CASE=?c, AGR=?a]\n",
      "NP[CASE=?c, AGR=?a] -> Det[CASE=?c, AGR=?a] N[CASE=?c, AGR=?a]\n",
      "VP[AGR=?a] -> IV[AGR=?a]\n",
      "VP[AGR=?a] -> TV[OBJCASE=?c, AGR=?a] NP[CASE=?c]\n",
      "# Lexical Productions\n",
      "# Singular determiners\n",
      "# masc\n",
      "Det[CASE=nom, AGR=[GND=masc,PER=3,NUM=sg]] -> 'der' \n",
      "Det[CASE=dat, AGR=[GND=masc,PER=3,NUM=sg]] -> 'dem'\n",
      "Det[CASE=acc, AGR=[GND=masc,PER=3,NUM=sg]] -> 'den'\n",
      "# fem\n",
      "Det[CASE=nom, AGR=[GND=fem,PER=3,NUM=sg]] -> 'die' \n",
      "Det[CASE=dat, AGR=[GND=fem,PER=3,NUM=sg]] -> 'der'\n",
      "Det[CASE=acc, AGR=[GND=fem,PER=3,NUM=sg]] -> 'die' \n",
      "# Plural determiners\n",
      "Det[CASE=nom, AGR=[PER=3,NUM=pl]] -> 'die' \n",
      "Det[CASE=dat, AGR=[PER=3,NUM=pl]] -> 'den' \n",
      "Det[CASE=acc, AGR=[PER=3,NUM=pl]] -> 'die' \n",
      "# Nouns\n",
      "N[AGR=[GND=masc,PER=3,NUM=sg]] -> 'Hund'\n",
      "N[CASE=nom, AGR=[GND=masc,PER=3,NUM=pl]] -> 'Hunde'\n",
      "N[CASE=dat, AGR=[GND=masc,PER=3,NUM=pl]] -> 'Hunden'\n",
      "N[CASE=acc, AGR=[GND=masc,PER=3,NUM=pl]] -> 'Hunde'\n",
      "N[AGR=[GND=fem,PER=3,NUM=sg]] -> 'Katze'\n",
      "N[AGR=[GND=fem,PER=3,NUM=pl]] -> 'Katzen'\n",
      "# Pronouns\n",
      "PRO[CASE=nom, AGR=[PER=1,NUM=sg]] -> 'ich'\n",
      "PRO[CASE=acc, AGR=[PER=1,NUM=sg]] -> 'mich'\n",
      "PRO[CASE=dat, AGR=[PER=1,NUM=sg]] -> 'mir'\n",
      "PRO[CASE=nom, AGR=[PER=2,NUM=sg]] -> 'du'\n",
      "PRO[CASE=nom, AGR=[PER=3,NUM=sg]] -> 'er' | 'sie' | 'es'\n",
      "PRO[CASE=nom, AGR=[PER=1,NUM=pl]] -> 'wir'\n",
      "PRO[CASE=acc, AGR=[PER=1,NUM=pl]] -> 'uns'\n",
      "PRO[CASE=dat, AGR=[PER=1,NUM=pl]] -> 'uns'\n",
      "PRO[CASE=nom, AGR=[PER=2,NUM=pl]] -> 'ihr'\n",
      "PRO[CASE=nom, AGR=[PER=3,NUM=pl]] -> 'sie'\n",
      "# Verbs\n",
      "IV[AGR=[NUM=sg,PER=1]] -> 'komme'\n",
      "IV[AGR=[NUM=sg,PER=2]] -> 'kommst'\n",
      "IV[AGR=[NUM=sg,PER=3]] -> 'kommt'\n",
      "IV[AGR=[NUM=pl, PER=1]] -> 'kommen'\n",
      "IV[AGR=[NUM=pl, PER=2]] -> 'kommt'\n",
      "IV[AGR=[NUM=pl, PER=3]] -> 'kommen'\n",
      "TV[OBJCASE=acc, AGR=[NUM=sg,PER=1]] -> 'sehe' | 'mag'\n",
      "TV[OBJCASE=acc, AGR=[NUM=sg,PER=2]] -> 'siehst' | 'magst'\n",
      "TV[OBJCASE=acc, AGR=[NUM=sg,PER=3]] -> 'sieht' | 'mag'\n",
      "TV[OBJCASE=dat, AGR=[NUM=sg,PER=1]] -> 'folge' | 'helfe'\n",
      "TV[OBJCASE=dat, AGR=[NUM=sg,PER=2]] -> 'folgst' | 'hilfst'\n",
      "TV[OBJCASE=dat, AGR=[NUM=sg,PER=3]] -> 'folgt' | 'hilft'\n",
      "TV[OBJCASE=acc, AGR=[NUM=pl,PER=1]] -> 'sehen' | 'moegen'\n",
      "TV[OBJCASE=acc, AGR=[NUM=pl,PER=2]] -> 'sieht' | 'moegt'\n",
      "TV[OBJCASE=acc, AGR=[NUM=pl,PER=3]] -> 'sehen' | 'moegen'\n",
      "TV[OBJCASE=dat, AGR=[NUM=pl,PER=1]] -> 'folgen' | 'helfen'\n",
      "TV[OBJCASE=dat, AGR=[NUM=pl,PER=2]] -> 'folgt' | 'helft'\n",
      "TV[OBJCASE=dat, AGR=[NUM=pl,PER=3]] -> 'folgen' | 'helfen'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('grammars/book_grammars/german.fcfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f169116",
   "metadata": {},
   "source": [
    "# 9.4 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29b53b",
   "metadata": {},
   "source": [
    "文脈自由文法で従来使われてきている範疇はアトミックな記号である．素性構造を用いる重要な動機として，より粒度の細かな識別に対応できることが挙げられる．ほかの方法ではアトミックな範疇を大幅に増やさなければならない．\n",
    "\n",
    "素性値に変数を用いることで文法生成規則における制約を表現することができ，異なる素性の指定を相互に依存させることができる．\n",
    "\n",
    "通常は語彙レベルには固定値の素性を割り当て，句の素性値を制限し，子の対応する値と単一化する．\n",
    "素性値はアトミック値もしくは複合型である．アトミック値の１つの特殊な場合としてブール値があり，これは慣例的に[+/- 素性]によって表される．\n",
    "\n",
    "素性同士が値（アトミック値，複合型を問わず）を共有することもできる，共通の値を持つ構造は歳入と呼ばれ，AVMにおいて共通の値は添え字（もしきはタグ）によって表現される．\n",
    "\n",
    "素性構造におけるパスは，グラフ表現の根から始まる弧を考えたときの，系列上のラベルに対応する素性のタプルである．\n",
    "\n",
    "２つのパスが値を共有している場合，そのパスは等価であるという．\n",
    "\n",
    "素性構造に対して包含関係によって半順序関係を定義できる．\n",
    "\n",
    "２つの素性構造について単一化が成功すれば両方を結合した情報を含む素性構造が作られる．\n",
    "\n",
    "単一化によってパスが具体化されれば，等価なパスがすべて具体化される．（更新）\n",
    "\n",
    "様々な言語的現象を簡単に解析するために素性構造を使うことができる．これには同氏の下位範疇化，転置構造，非有界依存構造，格による制約などが含まれる．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
